# DataAnalysis

------------------------------------------------------------------------------------------------------

LAB 1:

Виконати наступне: 
1) Завантажити дані, вивести назви колонок і розмір датасета
2) Опрацювати пропуски (по можливості заповнити їх або видалити)
3) Візуалізувати дані: побудувати графік (heatmap), що відображає кореляції
ознак між собою і з цільовою змінною (розміткою); побудувати гістограми
розподілу ознак і boxplot-и ознак відносно цільової змінної (якщо ознак занадто багато
обмежитися декількома)
4) Нормалізувати дані
5) Провести навчання наступних класифікаторів:
kNN
дерево прийняття рішень
SVM
Random Forest
AdaBoost
Підібрати оптимальні параметри
• для kNN
• для SVM за допомогою GridSearch підібрати оптимальні «C» і «gamma»
Серед обраних оптимальних моделей кожного класу вибрати найкращу.
Відобразити
sklearn.metrics.classification_report і sklearn.metrics.confusion_matrix

------------------------------------------------------------------------------------------------------

LAB-2:

1. Зниження розмірності і візуалізація даних
Застосуйте методи зниження розмірності sklearn.decomposition.PCA і sklearn.manifold.TSNE для візуалізації даних, з якими ви працювали в лабораторній № 1 (знижуючи розмірність до двох). Візуалізуйте результат.
2. Кластерний аналіз
1) За допомогою алгоритму k-means зробіть квантування зображення (видалення візуально надлишкової інформації) з глибиною 64, 32, 16 та 8 рівнів для будь-якого обраного самостійно зображення. Приклад: https://scikit-learn.org/stable/auto_examples/cluster/plot_color_quantization.html
3. Обробка та класифікація текстових даних
Завантажте набір текстових даних (з мітками класів). 
Проведіть передобробку даних (видаліть стоп-слова, пунктуацію), за допомогою wordcloud зробіть візуалізацію найбільш поширених слів або n-gram у кожному класі. 
Векторизуйте тексти (наприклад за допомогою sklearn.feature_extraction.text.TfidfVectorizer). 
Проведіть класифікацію текстових даних, зробіть оцінку якості.

------------------------------------------------------------------------------------------------------

LAB-3:

Знайомство з нейромережами (Framework: TensorFlow2 + Keras, можно використовувати Pytorch)

1. Повнозв'язані нейронні мережі
Вирішіть завдання класифікації даних, з якими ви працювали в лабораторній № 1 за допомогою повнозв’язаної нейромережі прямого поширення (fully connected feed-forward network). Результати порівняйте з одержаними раніше. 

2. Згорткові нейронні мережі
Вирішіть завдання класифікації зображень за допомогою згорткової (convolutional) нейромережі (якщо в обраному датасеті класів забагато, достатньо залишити 3-5).

3. Рекурентні нейронні мережі
Вирішіть задачу класифікації текстів (з якими ви працювали в лабораторній № 2) за допомогою рекурентної нейромережі. Результати порівняйте з одержаними раніш. 

------------------------------------------------------------------------------------------------------

LAB-4:

1. Генерація зображень
Вирішіть завдання генерації зображень (архітектура за вашим вибором: GAN/DCGAN/VAE), якщо в обраному датасеті багато класів, залиште декілька.
Датасети: можна брати CIFAR-100, Fashion MNIST або тут: https://www.kaggle.com/tags/image-data  

2.  Вирішити завдання машинного перекладу (будь яка пара мов, датасети тут: https://www.manythings.org/anki/)
Приклад: https://keras.io/examples/nlp/neural_machine_translation_with_transformer/ (English-to-Spanish не обирати!)

3. Проведіть експерименти з моделями бібліотеки HF Transformers (https://huggingface.co/) за допомогою (наприклад) Pipeline або TFAutoModelForSequenceClassification
Приклад: https://github.com/natsakh/Data-Analysis/blob/main/Pr_8/1%20hugging%20face%20transformers.ipynb

4. Бонус (не обов'язкова задача). Застосуйте pretrained BERT model для задачі класифікації текстів з лабораторної 2. 

------------------------------------------------------------------------------------------------------
